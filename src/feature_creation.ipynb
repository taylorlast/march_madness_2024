{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost\n",
    "\n",
    "import networkx\n",
    "from networkx.algorithms.traversal.depth_first_search import dfs_edges\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "data = dict()\n",
    "for dirname, _, filenames in os.walk('../kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        table_name = filename.split('.')[0]\n",
    "        table_path = os.path.join(dirname, filename)\n",
    "        try:\n",
    "            data[table_name] = pd.read_csv(table_path)\n",
    "        except UnicodeDecodeError:\n",
    "            data[table_name] = pd.read_csv(table_path, encoding='cp1252')\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {filename}: {e}\")\n",
    "\n",
    "# Split dict of dataframes by gender and other (supplemental) data\n",
    "mens_data = dict()\n",
    "womens_data = dict()\n",
    "supplemental_data = dict()\n",
    "\n",
    "for k, v in data.items():\n",
    "    if k.startswith(\"M\"):\n",
    "        mens_data[k] = v\n",
    "    elif k.startswith(\"W\"):\n",
    "        womens_data[k] = v\n",
    "    else:\n",
    "        supplemental_data[k] = v\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season_stats(dataset, detailed=False, post_season=False, year=None):\n",
    "    # Gets the first letter in dataset\n",
    "    gender = list(dataset.keys())[0][0]\n",
    "    \n",
    "    if detailed:\n",
    "        if post_season:\n",
    "            df = dataset[f\"{gender}NCAATourneyDetailedResults\"]\n",
    "        else:\n",
    "            df = dataset[f\"{gender}RegularSeasonDetailedResults\"]\n",
    "        \n",
    "    else:\n",
    "        if post_season:\n",
    "            df = dataset[f\"{gender}NCAATourneyCompactResults\"]\n",
    "        else:\n",
    "            df = dataset[f\"{gender}RegularSeasonCompactResults\"]\n",
    "    if year is not None:\n",
    "        df = df[df[\"Season\"] == year]\n",
    "    return df, gender\n",
    "\n",
    "def compute_margins_of_victory(df):\n",
    "    df[\"margin\"] = df[\"WScore\"] - df[\"LScore\"]\n",
    "    \n",
    "    win_df = df[[\"WTeamID\", \"margin\"]].rename(columns={\"WTeamID\": \"TeamID\"})\n",
    "    lose_df = df[[\"LTeamID\", \"margin\"]].rename(columns={\"LTeamID\": \"TeamID\"})\n",
    "    lose_df[\"margin\"] = -lose_df[\"margin\"]\n",
    "\n",
    "    res = pd.concat([win_df, lose_df], axis=0)\n",
    "    return res.groupby(\"TeamID\")[\"margin\"].mean()\n",
    "\n",
    "def join_team_names(df, data, gender=\"M\"):\n",
    "    \"\"\"\n",
    "    df: pd.DataFrame\n",
    "        dataframe appending teams to\n",
    "    data: dict[str, pd.DataFrame]\n",
    "        dictionary of all table names and data\n",
    "    \"\"\"\n",
    "    res = pd.merge(df, data[f\"{gender}Teams\"][[\"TeamID\", \"TeamName\"]], on=\"TeamID\")\n",
    "    return res\n",
    "\n",
    "def create_srs(df,gender):\n",
    "\n",
    "    df[\"margin\"] = df[\"WScore\"] - df[\"LScore\"]\n",
    "    win_df = df[[\"WTeamID\", \"margin\", \"LTeamID\"]].rename(\n",
    "        columns={\"WTeamID\": \"team_id\", \"LTeamID\": \"opp_id\"}\n",
    "    )\n",
    "    lose_df = df[[\"WTeamID\", \"margin\", \"LTeamID\"]].rename(\n",
    "        columns={\"LTeamID\": \"team_id\", \"WTeamID\": \"opp_id\"}\n",
    "    )\n",
    "    lose_df[\"margin\"] = -lose_df[\"margin\"]\n",
    "\n",
    "    teams = pd.concat([win_df, lose_df], axis=0)\n",
    "    spreads = compute_margins_of_victory(df)\n",
    "    \n",
    "    terms = []\n",
    "    solutions = []\n",
    "\n",
    "    for team_id in spreads.keys():\n",
    "        row = []\n",
    "        opps = list(teams[teams[\"team_id\"] == team_id][\"opp_id\"])\n",
    "\n",
    "        for opp_id in spreads.keys():\n",
    "            if opp_id == team_id:\n",
    "                # coef for the team itself should be 1\n",
    "                row.append(1)\n",
    "            elif opp_id in opps:\n",
    "                # coef for opponents is 1 over num of opps\n",
    "                row.append(-1.0/len(opps))\n",
    "            else:\n",
    "                # teams not faced get a 0 coef\n",
    "                row.append(0)\n",
    "        terms.append(row)\n",
    "\n",
    "        solutions.append(spreads[team_id])\n",
    "\n",
    "    solutions, _, _, _ = np.linalg.lstsq(np.array(terms), np.array(solutions), rcond=None)\n",
    "    \n",
    "    ratings = list(zip( spreads.keys(), solutions ))\n",
    "    srs = pd.DataFrame(ratings, columns=['team', 'rating'])\n",
    "    rankings = srs.sort_values('rating', ascending=False).reset_index()[['team', 'rating']]\n",
    "    rankings = join_team_names(rankings.rename(columns={\"team\": \"TeamID\"}), data, gender=gender)\n",
    "    return rankings\n",
    "\n",
    "def get_coach_win_perc(\n",
    "    dataset: dict,\n",
    "    regular_season: bool,\n",
    "    year:int = 2024\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    dataset: dict\n",
    "        dictionary of datasets to use. it will be\n",
    "        mens_data or womens_data.\n",
    "        \n",
    "    year: int\n",
    "        year to filter data. it will get coaches stats for everything\n",
    "        up until this year. (model can't have any look ahead bias). for post\n",
    "        season games, use a year one less than the year of interest.\n",
    "        \n",
    "    returns\n",
    "    -------\n",
    "    coaches_stats: pd.DataFrame\n",
    "        dataframe with count of wins, win percentage, and std dev\n",
    "        of wins.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Gets the first letter in dataset\n",
    "    gender = list(dataset.keys())[0][0]\n",
    "    \n",
    "    if regular_season:\n",
    "        df = dataset[f\"{gender}RegularSeasonCompactResults\"]\n",
    "        #Filter season up until season of interest\n",
    "        df = df[df[\"Season\"] <= year]\n",
    "    else:\n",
    "        df = dataset[f\"{gender}NCAATourneyCompactResults\"]\n",
    "        #Filter season up until season of interest\n",
    "        df = df[df[\"Season\"] < year]\n",
    "        \n",
    "    \n",
    "    \n",
    "    winning_coaches_df = pd.merge(\n",
    "        df,\n",
    "        dataset[f\"{gender}TeamCoaches\"],\n",
    "        how=\"left\",\n",
    "        left_on=[\"Season\", \"WTeamID\"],\n",
    "        right_on=[\"Season\", \"TeamID\"]\n",
    "    )\n",
    "\n",
    "    winning_coaches_df = winning_coaches_df[\n",
    "        (winning_coaches_df['DayNum'] >= winning_coaches_df['FirstDayNum']) \n",
    "        & (winning_coaches_df['DayNum'] <= winning_coaches_df['LastDayNum'])\n",
    "    ]\n",
    "    winning_coaches_df[\"win\"] = 1\n",
    "\n",
    "    #Make sure the join dind't create dupes\n",
    "    assert len(winning_coaches_df) == len(df)\n",
    "\n",
    "    losing_coaches_df = pd.merge(\n",
    "        df,\n",
    "        dataset[f\"{gender}TeamCoaches\"],\n",
    "        how=\"left\",\n",
    "        left_on=[\"Season\", \"LTeamID\"],\n",
    "        right_on=[\"Season\", \"TeamID\"]\n",
    "    )\n",
    "\n",
    "    losing_coaches_df = losing_coaches_df[\n",
    "        (losing_coaches_df['DayNum'] >= losing_coaches_df['FirstDayNum']) \n",
    "        & (losing_coaches_df['DayNum'] <= losing_coaches_df['LastDayNum'])\n",
    "    ]\n",
    "    losing_coaches_df[\"win\"] = 0\n",
    "\n",
    "    #Make sure the join dind't create dupes\n",
    "    assert len(losing_coaches_df) == len(df)\n",
    "\n",
    "    coaches_df = pd.concat(\n",
    "        [\n",
    "            losing_coaches_df[[\"CoachName\", \"win\"]],\n",
    "            winning_coaches_df[[\"CoachName\", \"win\"]]\n",
    "        ],\n",
    "        axis=0\n",
    "    )\n",
    "\n",
    "    coach_stats = (\n",
    "        coaches_df\n",
    "        .groupby(\"CoachName\")[\"win\"]\n",
    "        .describe()\n",
    "        .sort_values(\"count\", ascending=False)\n",
    "        [[\"count\", \"mean\", \"std\"]]\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    return coach_stats\n",
    "def get_system_ratings(\n",
    "    mens_dataset, #There are only ratings for men\n",
    "    systems: List[str],\n",
    "    year: int=2024,\n",
    "):\n",
    "    \"\"\"\n",
    "    gets system ratings for each team for specified systems for a specific year.\n",
    "    \n",
    "    parameters\n",
    "    ---------\n",
    "    mens_dataset: dict\n",
    "        dictionary of datasets for men\n",
    "    systems: List[str]\n",
    "        list of dictionaries we are interested in seeing\n",
    "    year: int\n",
    "        year to look for ratings\n",
    "    moving_average: str\n",
    "        specifies how to calculate rolling ratings for given systems.\n",
    "        if None, the system takes the most recent system rating\n",
    "    \n",
    "    returns\n",
    "    -------\n",
    "    df: pd.DataFrame\n",
    "        data that reflects ratings for a team\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter by season - only take most recent\n",
    "    df = mens_dataset[\"MMasseyOrdinals\"]\n",
    "    df = df[df[\"Season\"] == year]\n",
    "    \n",
    "    # Filter by system\n",
    "    df = df[df[\"SystemName\"].isin(systems)]\n",
    "    \n",
    "    latest_rank = (\n",
    "        df\n",
    "        .sort_values(\"RankingDayNum\")\n",
    "        .groupby([\"TeamID\",\"SystemName\"])\n",
    "        [\"OrdinalRank\"]\n",
    "        .last()\n",
    "        .unstack(\"SystemName\")\n",
    "        .reset_index().\n",
    "        rename(columns = {i: i+\"_latest\" for i in systems})\n",
    "    )\n",
    "    \n",
    "    transformed_df = (\n",
    "        df\n",
    "        .sort_values(by=\"RankingDayNum\")\n",
    "        .groupby([\"TeamID\", \"SystemName\"], group_keys=False)\n",
    "        [\"OrdinalRank\"]\n",
    "        .rolling(5) # TODO: Parameterize this (window and moving average method)\n",
    "        .mean()\n",
    "        .unstack(\"SystemName\")\n",
    "        .reset_index()\n",
    "        .drop(\"level_1\", axis=1)\n",
    "        .groupby(\"TeamID\")\n",
    "        [systems]\n",
    "        .last()\n",
    "        .reset_index()\n",
    "        .rename(columns = {i: i+\"_rolling\" for i in systems})\n",
    "    )\n",
    "    \n",
    "    res = pd.merge(latest_rank, transformed_df, on=\"TeamID\")\n",
    "\n",
    "    return res\n",
    "\n",
    "def get_post_season(data, year):\n",
    "    \n",
    "    df, gender = get_season_stats(\n",
    "            data, \n",
    "            detailed=False, \n",
    "            post_season=True, \n",
    "            year=year\n",
    "    )\n",
    "    \n",
    "    # Shuffle teams for positional encoding (model shouldn't have winning teams features as the same)\n",
    "    df[\"TeamID\"] = np.where(\n",
    "        np.random.uniform(0,1, size=len(df)) > .5, \n",
    "        df[\"WTeamID\"], \n",
    "        df[\"LTeamID\"]\n",
    "    )\n",
    "    df[\"team_score\"] = np.where(\n",
    "        df[\"TeamID\"] == df[\"WTeamID\"], \n",
    "        df[\"WScore\"], \n",
    "        df[\"LScore\"]\n",
    "    )\n",
    "    df[\"OppID\"] = np.where(\n",
    "        df[\"TeamID\"] == df[\"WTeamID\"], \n",
    "        df[\"LTeamID\"], \n",
    "        df[\"WTeamID\"]\n",
    "    )\n",
    "    df[\"opp_score\"] = np.where(\n",
    "        df[\"TeamID\"] == df[\"WTeamID\"], \n",
    "        df[\"LScore\"], \n",
    "        df[\"WScore\"]\n",
    "    )\n",
    "    df = df.drop(\n",
    "        [\"WTeamID\", \"LTeamID\", \"WScore\", \"LScore\", \"WLoc\", \"NumOT\"],\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_features(mens_data, year, systems):\n",
    "    # Season Stats\n",
    "    df, gender = get_season_stats(\n",
    "        mens_data, \n",
    "        detailed=False, \n",
    "        post_season=False, \n",
    "        year=year\n",
    "    )\n",
    "\n",
    "    # Rating System\n",
    "    srs = create_srs(df, gender)\n",
    "\n",
    "    # System Ratings\n",
    "    system_ratings = get_system_ratings(\n",
    "        mens_data, \n",
    "        systems=systems\n",
    "    ) #KenPom, Nolan ELO, EPSN BPI\n",
    "\n",
    "    # Ratings df\n",
    "    ratings_df = pd.merge(\n",
    "                srs,\n",
    "                system_ratings,\n",
    "                on=\"TeamID\"\n",
    "    )\n",
    "\n",
    "    # Coaches postseason win stats\n",
    "    coaches_postseason_win_df = get_coach_win_perc(\n",
    "        dataset=mens_data, \n",
    "        regular_season=False, \n",
    "        year=year\n",
    "    ).rename(columns={\"count\": \"count_post\", \"mean\": \"mean_post\", \"std\": \"std_post\"})\n",
    "\n",
    "    # Coaches regular season win stats\n",
    "    coaches_regseason_win_df = get_coach_win_perc(\n",
    "        dataset=mens_data, \n",
    "        regular_season=True, \n",
    "        year=year\n",
    "    ).rename(columns={\"count\": \"count_reg\", \"mean\": \"mean_reg\", \"std\": \"std_reg\"})\n",
    "\n",
    "    coaches_df = pd.merge(\n",
    "        coaches_regseason_win_df,\n",
    "        coaches_postseason_win_df,\n",
    "        on=\"CoachName\",\n",
    "        how=\"left\"\n",
    "    ).fillna(0)\n",
    "\n",
    "    # Get coaches for the year and only grab the most recent coach for a certain team\n",
    "    curr_coaches = (\n",
    "        mens_data[\"MTeamCoaches\"][\n",
    "            mens_data[\"MTeamCoaches\"][\"Season\"] == year\n",
    "        ]\n",
    "        .sort_values(\"FirstDayNum\")\n",
    "        .groupby(\"TeamID\")[\"CoachName\"]\n",
    "        .last()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Get coach stats for current coaches\n",
    "    coaches_df = pd.merge(\n",
    "        curr_coaches,\n",
    "        coaches_df,\n",
    "        on=\"CoachName\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "\n",
    "    feature_df = (\n",
    "        pd.merge(\n",
    "            ratings_df,\n",
    "            coaches_df\n",
    "        )\n",
    "        .drop([\"TeamName\", \"CoachName\"], axis=1)\n",
    "    )\n",
    "\n",
    "    \n",
    "    return feature_df\n",
    "\n",
    "\n",
    "def merge_features_to_games(feature_df, post_season_df, year, training=True):\n",
    "    \n",
    "    post_season_merged = pd.merge(\n",
    "        pd.merge(\n",
    "            feature_df,\n",
    "            post_season_df,\n",
    "            on=\"TeamID\",\n",
    "        ),\n",
    "        feature_df,\n",
    "        left_on=\"OppID\",\n",
    "        right_on=\"TeamID\",\n",
    "        suffixes=(\"_team\", \"_opp\")\n",
    "    )\n",
    "    if training:\n",
    "        post_season_merged[\"win\"] = post_season_merged[\"team_score\"] > post_season_merged[\"opp_score\"]\n",
    "        post_season_merged = (\n",
    "            post_season_merged\n",
    "            .drop(\n",
    "                [\"TeamID_team\", \"team_score\", \"OppID\", \"TeamID_opp\", \"opp_score\", \"DayNum\"], \n",
    "                axis=1\n",
    "            )\n",
    "        )\n",
    "    return post_season_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['MConferenceTourneyGames', 'MGameCities', 'MMasseyOrdinals', 'MNCAATourneyCompactResults', 'MNCAATourneyDetailedResults', 'MNCAATourneySeedRoundSlots', 'MNCAATourneySeeds', 'MNCAATourneySlots', 'MRegularSeasonCompactResults', 'MRegularSeasonDetailedResults', 'MSeasons', 'MSecondaryTourneyCompactResults', 'MSecondaryTourneyTeams', 'MTeamCoaches', 'MTeamConferences', 'MTeams', 'MTeamSpellings'])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mens_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Season', 'DayNum', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'WLoc',\n",
       "       'NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR',\n",
       "       'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3',\n",
       "       'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = mens_data[\"MRegularSeasonDetailedResults\"]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2023, _ = get_season_stats(\n",
    "    mens_data,\n",
    "    detailed=True,\n",
    "    post_season=False,\n",
    "    year=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_stats(df):\n",
    "\n",
    "    df[\"margin\"] = df[\"WScore\"] - df[\"LScore\"]\n",
    "    win_df = df.rename(\n",
    "        columns={\"WTeamID\": \"team_id\", \"LTeamID\": \"opp_id\", \"WLoc\": \"Loc\"}\n",
    "    )\n",
    "    win_df = win_df.rename(columns={col: col[1:] + \"_opp\" for col in win_df.columns if col.startswith(\"L\") and col != \"Loc\"})\n",
    "    win_df = win_df.rename(columns={col: col[1:] for col in win_df.columns if col.startswith(\"W\") and not col.endswith(\"_opp\")})\n",
    "    \n",
    "    lose_df = df.rename(\n",
    "        columns={\"LTeamID\": \"team_id\", \"WTeamID\": \"opp_id\", \"WLoc\": \"Loc\"}\n",
    "    )\n",
    "    lose_df = lose_df.rename(columns={col: col[1:] for col in lose_df.columns if col.startswith(\"L\") and col != \"Loc\"})\n",
    "    lose_df = lose_df.rename(columns={col: col[1:] + \"_opp\" for col in lose_df.columns if col.startswith(\"W\")})\n",
    "    lose_df[\"Loc\"] = lose_df[\"Loc\"].apply(lambda x: \"H\" if x == \"A\" else \"A\" if x == \"H\" else \"N\")\n",
    "    lose_df[\"margin\"] = -lose_df[\"margin\"]\n",
    "\n",
    "    teams = pd.concat([win_df, lose_df], axis=0)\n",
    "\n",
    "    df = teams.groupby([\"Season\", \"team_id\"])[\n",
    "        ['FGM', 'FGA', 'FGM3', 'FGA3', 'FTM', 'FTA', 'OR', 'DR', 'Ast',\n",
    "        'TO', 'Stl', 'Blk', 'PF', 'FGM_opp', 'FGA_opp', 'FGM3_opp', 'FGA3_opp',\n",
    "        'FTM_opp', 'FTA_opp', 'OR_opp', 'DR_opp', 'Ast_opp', 'TO_opp',\n",
    "        'Stl_opp', 'Blk_opp', 'PF_opp', 'margin'\n",
    "        ]\n",
    "    ].agg([\n",
    "            (\"mean\", \"mean\"), \n",
    "            (\"quant25\" , lambda x: x.quantile(.25)), \n",
    "            (\"quant75\", lambda x: x.quantile(.75))\n",
    "        ]\n",
    "    ).reset_index()\n",
    "    df.columns = [(col + \"_\" + agg_func).strip(\"_\") for col, agg_func in zip(df.columns.get_level_values(0), df.columns.get_level_values(1))]\n",
    "\n",
    "    for col in df.columns:\n",
    "        if (\n",
    "            \"_opp\" in col\n",
    "            and col.replace(\"_opp\", \"\") in df.columns \n",
    "            and col not in [\"Season\", \"team_id\"]\n",
    "        ):\n",
    "            new_col = col.replace(\"_opp\", \"\") + \"_diff\"\n",
    "            df[new_col] = df[col.replace(\"_opp\", \"\")] - df[col]\n",
    "            df = df.drop([col.replace(\"_opp\", \"\"), col], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_team_stats(df_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>team_id</th>\n",
       "      <th>margin_mean</th>\n",
       "      <th>margin_quant25</th>\n",
       "      <th>margin_quant75</th>\n",
       "      <th>FGM_mean_diff</th>\n",
       "      <th>FGM_quant25_diff</th>\n",
       "      <th>FGM_quant75_diff</th>\n",
       "      <th>FGA_mean_diff</th>\n",
       "      <th>FGA_quant25_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>TO_quant75_diff</th>\n",
       "      <th>Stl_mean_diff</th>\n",
       "      <th>Stl_quant25_diff</th>\n",
       "      <th>Stl_quant75_diff</th>\n",
       "      <th>Blk_mean_diff</th>\n",
       "      <th>Blk_quant25_diff</th>\n",
       "      <th>Blk_quant75_diff</th>\n",
       "      <th>PF_mean_diff</th>\n",
       "      <th>PF_quant25_diff</th>\n",
       "      <th>PF_quant75_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>1102</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-13.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-2.642857</td>\n",
       "      <td>-2.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>1103</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>-6.50</td>\n",
       "      <td>6.00</td>\n",
       "      <td>-0.629630</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.148148</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.518519</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-2.592593</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>-4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>1104</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>-4.25</td>\n",
       "      <td>11.25</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.678571</td>\n",
       "      <td>2.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.75</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.214286</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>1105</td>\n",
       "      <td>-4.884615</td>\n",
       "      <td>-11.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-2.615385</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-2.75</td>\n",
       "      <td>2.653846</td>\n",
       "      <td>4.25</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.076923</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-2.115385</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>1.153846</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>1106</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>-6.75</td>\n",
       "      <td>6.75</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1.892857</td>\n",
       "      <td>2.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>-0.428571</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.035714</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>2.035714</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>2024</td>\n",
       "      <td>1474</td>\n",
       "      <td>-5.928571</td>\n",
       "      <td>-16.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>-3.785714</td>\n",
       "      <td>-3.25</td>\n",
       "      <td>-4.25</td>\n",
       "      <td>-2.285714</td>\n",
       "      <td>-5.75</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.964286</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>-2.25</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7613</th>\n",
       "      <td>2024</td>\n",
       "      <td>1475</td>\n",
       "      <td>-8.115385</td>\n",
       "      <td>-12.75</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>-1.769231</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>2.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-0.846154</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.961538</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7614</th>\n",
       "      <td>2024</td>\n",
       "      <td>1476</td>\n",
       "      <td>-13.571429</td>\n",
       "      <td>-17.25</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>-3.750000</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>-3.107143</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>...</td>\n",
       "      <td>3.25</td>\n",
       "      <td>-1.464286</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>-2.035714</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>1.464286</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7615</th>\n",
       "      <td>2024</td>\n",
       "      <td>1477</td>\n",
       "      <td>-10.520000</td>\n",
       "      <td>-22.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-3.800000</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>-6.00</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>2.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7616</th>\n",
       "      <td>2024</td>\n",
       "      <td>1478</td>\n",
       "      <td>-3.400000</td>\n",
       "      <td>-16.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>-1.800000</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7617 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Season  team_id  margin_mean  margin_quant25  margin_quant75  \\\n",
       "0       2003     1102     0.250000          -13.00           10.00   \n",
       "1       2003     1103     0.629630           -6.50            6.00   \n",
       "2       2003     1104     4.285714           -4.25           11.25   \n",
       "3       2003     1105    -4.884615          -11.75            0.50   \n",
       "4       2003     1106    -0.142857           -6.75            6.75   \n",
       "...      ...      ...          ...             ...             ...   \n",
       "7612    2024     1474    -5.928571          -16.00            3.75   \n",
       "7613    2024     1475    -8.115385          -12.75           -2.00   \n",
       "7614    2024     1476   -13.571429          -17.25           -5.00   \n",
       "7615    2024     1477   -10.520000          -22.00            2.00   \n",
       "7616    2024     1478    -3.400000          -16.00            8.00   \n",
       "\n",
       "      FGM_mean_diff  FGM_quant25_diff  FGM_quant75_diff  FGA_mean_diff  \\\n",
       "0         -0.142857              0.00              0.00      -2.642857   \n",
       "1         -0.629630             -1.50              1.00      -1.148148   \n",
       "2          0.785714             -1.00              2.00       1.678571   \n",
       "3         -2.615385             -1.25             -2.75       2.653846   \n",
       "4          1.714286              1.00              2.25       1.892857   \n",
       "...             ...               ...               ...            ...   \n",
       "7612      -3.785714             -3.25             -4.25      -2.285714   \n",
       "7613      -1.769231             -2.00             -1.50       0.423077   \n",
       "7614      -3.750000             -2.00             -3.50      -3.107143   \n",
       "7615      -3.800000             -2.00             -6.00       2.200000   \n",
       "7616      -1.800000             -3.00             -1.00      -0.200000   \n",
       "\n",
       "      FGA_quant25_diff  ...  TO_quant75_diff  Stl_mean_diff  Stl_quant25_diff  \\\n",
       "0                -2.75  ...             0.00       0.535714              1.00   \n",
       "1                -1.50  ...            -2.50       0.851852              0.00   \n",
       "2                 2.00  ...            -2.75       1.071429              1.00   \n",
       "3                 4.25  ...            -1.00      -0.076923             -0.75   \n",
       "4                 2.00  ...             3.50      -0.428571             -0.75   \n",
       "...                ...  ...              ...            ...               ...   \n",
       "7612             -5.75  ...             1.00       0.142857              1.00   \n",
       "7613              2.00  ...             2.00      -0.846154              0.00   \n",
       "7614             -1.25  ...             3.25      -1.464286             -1.00   \n",
       "7615              2.00  ...            -2.00       1.600000             -1.00   \n",
       "7616              1.00  ...            -3.00       0.880000              1.00   \n",
       "\n",
       "      Stl_quant75_diff  Blk_mean_diff  Blk_quant25_diff  Blk_quant75_diff  \\\n",
       "0                 0.00       0.214286              1.00             -1.00   \n",
       "1                 1.00      -0.518519             -0.50             -0.50   \n",
       "2                 1.25       0.607143              1.00              0.00   \n",
       "3                 1.00      -2.115385             -1.25             -2.00   \n",
       "4                 0.75      -0.035714              0.00             -0.75   \n",
       "...                ...            ...               ...               ...   \n",
       "7612              1.00      -1.964286             -2.00             -2.25   \n",
       "7613             -2.00      -1.000000             -1.00             -1.00   \n",
       "7614             -2.00      -2.035714             -1.75             -3.00   \n",
       "7615              2.00       0.960000              0.00              2.00   \n",
       "7616              1.00       0.440000              1.00              1.00   \n",
       "\n",
       "      PF_mean_diff  PF_quant25_diff  PF_quant75_diff  \n",
       "0         0.392857             0.75             0.75  \n",
       "1        -2.592593            -2.00            -4.00  \n",
       "2        -1.214286            -1.75            -1.00  \n",
       "3         1.153846             1.00             0.25  \n",
       "4         2.035714             3.00             1.00  \n",
       "...            ...              ...              ...  \n",
       "7612     -0.714286            -1.25            -2.00  \n",
       "7613      2.961538             3.00             1.50  \n",
       "7614      1.464286             1.00             1.00  \n",
       "7615      3.320000             3.00             2.00  \n",
       "7616      1.800000             2.00             1.00  \n",
       "\n",
       "[7617 rows x 44 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import pandas as pd\n",
    "\n",
    "# def get_advanced_stats(year):\n",
    "    \n",
    "#     ################################## TEAM ##########################################\n",
    "\n",
    "\n",
    "#     # URL of the page you want to scrape\n",
    "#     url = f'https://www.sports-reference.com/cbb/seasons/men/{year}-advanced-school-stats.html'\n",
    "\n",
    "#     # Send a GET request to the webpage\n",
    "#     response = requests.get(url)\n",
    "\n",
    "#     # Parse the HTML content of the page\n",
    "#     soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "#     # Find the table by ID or class\n",
    "#     table = soup.find('table', {'id': 'adv_school_stats'})\n",
    "\n",
    "#     # Extract the column headers from the <thead> part of the table\n",
    "#     headers = [header.text for header in table.find('thead').find_all('th')]\n",
    "#     headers = [\n",
    "#         i for i in headers \n",
    "#         if (i != \"\") \n",
    "#         and (i != \"\\xa0\") \n",
    "#         and (i not in ['School Advanced', 'Overall', 'Conf.', 'Home', 'Away', 'Points', 'Opponent Advanced', 'Rk'])\n",
    "#     ]\n",
    "\n",
    "#     # Extract rows from the <tbody> part of the table\n",
    "#     rows = table.find('tbody').find_all('tr')\n",
    "\n",
    "#     # Extract data from each row\n",
    "#     data = []\n",
    "#     for row in rows:\n",
    "#         cols = row.find_all('td')\n",
    "#         cols = [ele.text.strip() for ele in cols if ele.text.strip() != \"\"]\n",
    "#         data.append(cols)  # Get rid of empty values\n",
    "\n",
    "#     # Create the DataFrame\n",
    "#     df = pd.DataFrame(data, columns=headers)  # headers[1:] because the first header is usually the rank or an empty string\n",
    "\n",
    "\n",
    "#     ################################## OPP ##########################################\n",
    "\n",
    "#     # URL of the page you want to scrape\n",
    "#     url = f'https://www.sports-reference.com/cbb/seasons/men/{year}-advanced-opponent-stats.html'\n",
    "\n",
    "#     # Send a GET request to the webpage\n",
    "#     response = requests.get(url)\n",
    "\n",
    "#     # Parse the HTML content of the page\n",
    "#     soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "#     # Find the table by ID or class\n",
    "#     table = soup.find('table', {'id': 'adv_opp_stats'})\n",
    "\n",
    "#     # Extract the column headers from the <thead> part of the table\n",
    "#     headers = [header.text for header in table.find('thead').find_all('th')]\n",
    "#     headers = [\n",
    "#         i for i in headers \n",
    "#         if (i != \"\") \n",
    "#         and (i != \"\\xa0\") \n",
    "#         and (i not in ['Overall', 'Conf.', 'Home', 'Away', 'Points', 'Opponent Advanced', 'Rk'])\n",
    "#     ]\n",
    "\n",
    "#     # Extract rows from the <tbody> part of the table\n",
    "#     rows = table.find('tbody').find_all('tr')\n",
    "\n",
    "#     # Extract data from each row\n",
    "#     data = []\n",
    "#     for row in rows:\n",
    "#         cols = row.find_all('td')\n",
    "#         cols = [ele.text.strip() for ele in cols if ele.text.strip() != \"\"]\n",
    "#         data.append(cols)  # Get rid of empty values\n",
    "\n",
    "#     # Create the DataFrame\n",
    "#     opp_df = pd.DataFrame(data, columns=headers)  # headers[1:] because the first header is usually the rank or an empty string\n",
    "\n",
    "#     df = df.dropna().reset_index(drop=True)\n",
    "#     opp_df = (\n",
    "#         opp_df\n",
    "#         .dropna()\n",
    "#         .reset_index(drop=True)\n",
    "#         .drop([\"G\", \"W\", \"L\", \"W-L%\", \"SRS\", \"SOS\", \"W\", \"L\", \"W\", \"L\", \"W\", \"L\", \"Tm.\", \"Opp.\"], axis=1)\n",
    "#         .rename(columns={col: col + \"_opp\" for col in opp_df.columns if col != \"School\"})\n",
    "#     )\n",
    "#     res = pd.merge(df, opp_df, on=\"School\")\n",
    "\n",
    "#     res[\"School\"] = res[\"School\"].str.replace(\"NCAA\",\"\").str.strip()\n",
    "\n",
    "#     return res\n",
    "\n",
    "\n",
    "# # Works 2010 and on\n",
    "# advanced_stats = dict()\n",
    "# for year in range(2010, 2025):\n",
    "#     print(year)\n",
    "#     advanced_stats[year] = get_advanced_stats(year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mm_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
