{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6y/6p7qrh9s27d1s3l8p2l81vbw0000gn/T/ipykernel_3427/1596029284.py:6: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost\n",
    "\n",
    "import networkx\n",
    "from networkx.algorithms.traversal.depth_first_search import dfs_edges\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "data = dict()\n",
    "for dirname, _, filenames in os.walk('../kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        table_name = filename.split('.')[0]\n",
    "        table_path = os.path.join(dirname, filename)\n",
    "        try:\n",
    "            data[table_name] = pd.read_csv(table_path)\n",
    "        except UnicodeDecodeError:\n",
    "            data[table_name] = pd.read_csv(table_path, encoding='cp1252')\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {filename}: {e}\")\n",
    "\n",
    "# Split dict of dataframes by gender and other (supplemental) data\n",
    "mens_data = dict()\n",
    "womens_data = dict()\n",
    "supplemental_data = dict()\n",
    "\n",
    "for k, v in data.items():\n",
    "    if k.startswith(\"M\"):\n",
    "        mens_data[k] = v\n",
    "    elif k.startswith(\"W\"):\n",
    "        womens_data[k] = v\n",
    "    else:\n",
    "        supplemental_data[k] = v\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season_stats(dataset, detailed=False, post_season=False, year=None):\n",
    "    # Gets the first letter in dataset\n",
    "    gender = list(dataset.keys())[0][0]\n",
    "    \n",
    "    if detailed:\n",
    "        if post_season:\n",
    "            df = dataset[f\"{gender}NCAATourneyDetailedResults\"]\n",
    "        else:\n",
    "            df = dataset[f\"{gender}RegularSeasonDetailedResults\"]\n",
    "        \n",
    "    else:\n",
    "        if post_season:\n",
    "            df = dataset[f\"{gender}NCAATourneyCompactResults\"]\n",
    "        else:\n",
    "            df = dataset[f\"{gender}RegularSeasonCompactResults\"]\n",
    "    if year is not None:\n",
    "        df = df[df[\"Season\"] == year]\n",
    "    return df, gender\n",
    "\n",
    "def compute_margins_of_victory(df):\n",
    "    df[\"margin\"] = df[\"WScore\"] - df[\"LScore\"]\n",
    "    \n",
    "    win_df = df[[\"WTeamID\", \"margin\"]].rename(columns={\"WTeamID\": \"TeamID\"})\n",
    "    lose_df = df[[\"LTeamID\", \"margin\"]].rename(columns={\"LTeamID\": \"TeamID\"})\n",
    "    lose_df[\"margin\"] = -lose_df[\"margin\"]\n",
    "\n",
    "    res = pd.concat([win_df, lose_df], axis=0)\n",
    "    return res.groupby(\"TeamID\")[\"margin\"].mean()\n",
    "\n",
    "def join_team_names(df, data, gender=\"M\"):\n",
    "    \"\"\"\n",
    "    df: pd.DataFrame\n",
    "        dataframe appending teams to\n",
    "    data: dict[str, pd.DataFrame]\n",
    "        dictionary of all table names and data\n",
    "    \"\"\"\n",
    "    res = pd.merge(df, data[f\"{gender}Teams\"][[\"TeamID\", \"TeamName\"]], on=\"TeamID\")\n",
    "    return res\n",
    "\n",
    "def create_srs(df,gender):\n",
    "\n",
    "    df[\"margin\"] = df[\"WScore\"] - df[\"LScore\"]\n",
    "    win_df = df[[\"WTeamID\", \"margin\", \"LTeamID\"]].rename(\n",
    "        columns={\"WTeamID\": \"team_id\", \"LTeamID\": \"opp_id\"}\n",
    "    )\n",
    "    lose_df = df[[\"WTeamID\", \"margin\", \"LTeamID\"]].rename(\n",
    "        columns={\"LTeamID\": \"team_id\", \"WTeamID\": \"opp_id\"}\n",
    "    )\n",
    "    lose_df[\"margin\"] = -lose_df[\"margin\"]\n",
    "\n",
    "    teams = pd.concat([win_df, lose_df], axis=0)\n",
    "    spreads = compute_margins_of_victory(df)\n",
    "    \n",
    "    terms = []\n",
    "    solutions = []\n",
    "\n",
    "    for team_id in spreads.keys():\n",
    "        row = []\n",
    "        opps = list(teams[teams[\"team_id\"] == team_id][\"opp_id\"])\n",
    "\n",
    "        for opp_id in spreads.keys():\n",
    "            if opp_id == team_id:\n",
    "                # coef for the team itself should be 1\n",
    "                row.append(1)\n",
    "            elif opp_id in opps:\n",
    "                # coef for opponents is 1 over num of opps\n",
    "                row.append(-1.0/len(opps))\n",
    "            else:\n",
    "                # teams not faced get a 0 coef\n",
    "                row.append(0)\n",
    "        terms.append(row)\n",
    "\n",
    "        solutions.append(spreads[team_id])\n",
    "\n",
    "    solutions, _, _, _ = np.linalg.lstsq(np.array(terms), np.array(solutions), rcond=None)\n",
    "    \n",
    "    ratings = list(zip( spreads.keys(), solutions ))\n",
    "    srs = pd.DataFrame(ratings, columns=['team', 'rating'])\n",
    "    rankings = srs.sort_values('rating', ascending=False).reset_index()[['team', 'rating']]\n",
    "    rankings = join_team_names(rankings.rename(columns={\"team\": \"TeamID\"}), data, gender=gender)\n",
    "    return rankings\n",
    "\n",
    "def get_coach_win_perc(\n",
    "    dataset: dict,\n",
    "    regular_season: bool,\n",
    "    year:int = 2024\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    dataset: dict\n",
    "        dictionary of datasets to use. it will be\n",
    "        mens_data or womens_data.\n",
    "        \n",
    "    year: int\n",
    "        year to filter data. it will get coaches stats for everything\n",
    "        up until this year. (model can't have any look ahead bias). for post\n",
    "        season games, use a year one less than the year of interest.\n",
    "        \n",
    "    returns\n",
    "    -------\n",
    "    coaches_stats: pd.DataFrame\n",
    "        dataframe with count of wins, win percentage, and std dev\n",
    "        of wins.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Gets the first letter in dataset\n",
    "    gender = list(dataset.keys())[0][0]\n",
    "    \n",
    "    if regular_season:\n",
    "        df = dataset[f\"{gender}RegularSeasonCompactResults\"]\n",
    "        #Filter season up until season of interest\n",
    "        df = df[df[\"Season\"] <= year]\n",
    "    else:\n",
    "        df = dataset[f\"{gender}NCAATourneyCompactResults\"]\n",
    "        #Filter season up until season of interest\n",
    "        df = df[df[\"Season\"] < year]\n",
    "        \n",
    "    \n",
    "    \n",
    "    winning_coaches_df = pd.merge(\n",
    "        df,\n",
    "        dataset[f\"{gender}TeamCoaches\"],\n",
    "        how=\"left\",\n",
    "        left_on=[\"Season\", \"WTeamID\"],\n",
    "        right_on=[\"Season\", \"TeamID\"]\n",
    "    )\n",
    "\n",
    "    winning_coaches_df = winning_coaches_df[\n",
    "        (winning_coaches_df['DayNum'] >= winning_coaches_df['FirstDayNum']) \n",
    "        & (winning_coaches_df['DayNum'] <= winning_coaches_df['LastDayNum'])\n",
    "    ]\n",
    "    winning_coaches_df[\"win\"] = 1\n",
    "\n",
    "    #Make sure the join dind't create dupes\n",
    "    assert len(winning_coaches_df) == len(df)\n",
    "\n",
    "    losing_coaches_df = pd.merge(\n",
    "        df,\n",
    "        dataset[f\"{gender}TeamCoaches\"],\n",
    "        how=\"left\",\n",
    "        left_on=[\"Season\", \"LTeamID\"],\n",
    "        right_on=[\"Season\", \"TeamID\"]\n",
    "    )\n",
    "\n",
    "    losing_coaches_df = losing_coaches_df[\n",
    "        (losing_coaches_df['DayNum'] >= losing_coaches_df['FirstDayNum']) \n",
    "        & (losing_coaches_df['DayNum'] <= losing_coaches_df['LastDayNum'])\n",
    "    ]\n",
    "    losing_coaches_df[\"win\"] = 0\n",
    "\n",
    "    #Make sure the join dind't create dupes\n",
    "    assert len(losing_coaches_df) == len(df)\n",
    "\n",
    "    coaches_df = pd.concat(\n",
    "        [\n",
    "            losing_coaches_df[[\"CoachName\", \"win\"]],\n",
    "            winning_coaches_df[[\"CoachName\", \"win\"]]\n",
    "        ],\n",
    "        axis=0\n",
    "    )\n",
    "\n",
    "    coach_stats = (\n",
    "        coaches_df\n",
    "        .groupby(\"CoachName\")[\"win\"]\n",
    "        .describe()\n",
    "        .sort_values(\"count\", ascending=False)\n",
    "        [[\"count\", \"mean\", \"std\"]]\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    return coach_stats\n",
    "def get_system_ratings(\n",
    "    mens_dataset, #There are only ratings for men\n",
    "    systems: List[str],\n",
    "    year: int=2024,\n",
    "):\n",
    "    \"\"\"\n",
    "    gets system ratings for each team for specified systems for a specific year.\n",
    "    \n",
    "    parameters\n",
    "    ---------\n",
    "    mens_dataset: dict\n",
    "        dictionary of datasets for men\n",
    "    systems: List[str]\n",
    "        list of dictionaries we are interested in seeing\n",
    "    year: int\n",
    "        year to look for ratings\n",
    "    moving_average: str\n",
    "        specifies how to calculate rolling ratings for given systems.\n",
    "        if None, the system takes the most recent system rating\n",
    "    \n",
    "    returns\n",
    "    -------\n",
    "    df: pd.DataFrame\n",
    "        data that reflects ratings for a team\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter by season - only take most recent\n",
    "    df = mens_dataset[\"MMasseyOrdinals\"]\n",
    "    df = df[df[\"Season\"] == year]\n",
    "    \n",
    "    # Filter by system\n",
    "    df = df[df[\"SystemName\"].isin(systems)]\n",
    "    \n",
    "    latest_rank = (\n",
    "        df\n",
    "        .sort_values(\"RankingDayNum\")\n",
    "        .groupby([\"TeamID\",\"SystemName\"])\n",
    "        [\"OrdinalRank\"]\n",
    "        .last()\n",
    "        .unstack(\"SystemName\")\n",
    "        .reset_index().\n",
    "        rename(columns = {i: i+\"_latest\" for i in systems})\n",
    "    )\n",
    "    \n",
    "    transformed_df = (\n",
    "        df\n",
    "        .sort_values(by=\"RankingDayNum\")\n",
    "        .groupby([\"TeamID\", \"SystemName\"], group_keys=False)\n",
    "        [\"OrdinalRank\"]\n",
    "        .rolling(5) # TODO: Parameterize this (window and moving average method)\n",
    "        .mean()\n",
    "        .unstack(\"SystemName\")\n",
    "        .reset_index()\n",
    "        .drop(\"level_1\", axis=1)\n",
    "        .groupby(\"TeamID\")\n",
    "        [systems]\n",
    "        .last()\n",
    "        .reset_index()\n",
    "        .rename(columns = {i: i+\"_rolling\" for i in systems})\n",
    "    )\n",
    "    \n",
    "    res = pd.merge(latest_rank, transformed_df, on=\"TeamID\")\n",
    "\n",
    "    return res\n",
    "\n",
    "def get_post_season(data, year):\n",
    "    \n",
    "    df, gender = get_season_stats(\n",
    "            data, \n",
    "            detailed=False, \n",
    "            post_season=True, \n",
    "            year=year\n",
    "    )\n",
    "    \n",
    "    # Shuffle teams for positional encoding (model shouldn't have winning teams features as the same)\n",
    "    df[\"TeamID\"] = np.where(\n",
    "        np.random.uniform(0,1, size=len(df)) > .5, \n",
    "        df[\"WTeamID\"], \n",
    "        df[\"LTeamID\"]\n",
    "    )\n",
    "    df[\"team_score\"] = np.where(\n",
    "        df[\"TeamID\"] == df[\"WTeamID\"], \n",
    "        df[\"WScore\"], \n",
    "        df[\"LScore\"]\n",
    "    )\n",
    "    df[\"OppID\"] = np.where(\n",
    "        df[\"TeamID\"] == df[\"WTeamID\"], \n",
    "        df[\"LTeamID\"], \n",
    "        df[\"WTeamID\"]\n",
    "    )\n",
    "    df[\"opp_score\"] = np.where(\n",
    "        df[\"TeamID\"] == df[\"WTeamID\"], \n",
    "        df[\"LScore\"], \n",
    "        df[\"WScore\"]\n",
    "    )\n",
    "    df = df.drop(\n",
    "        [\"WTeamID\", \"LTeamID\", \"WScore\", \"LScore\", \"WLoc\", \"NumOT\"],\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_features(mens_data, year, systems):\n",
    "    # Season Stats\n",
    "    df, gender = get_season_stats(\n",
    "        mens_data, \n",
    "        detailed=False, \n",
    "        post_season=False, \n",
    "        year=year\n",
    "    )\n",
    "\n",
    "    # Rating System\n",
    "    srs = create_srs(df, gender)\n",
    "\n",
    "    # System Ratings\n",
    "    system_ratings = get_system_ratings(\n",
    "        mens_data, \n",
    "        systems=systems\n",
    "    ) #KenPom, Nolan ELO, EPSN BPI\n",
    "\n",
    "    # Ratings df\n",
    "    ratings_df = pd.merge(\n",
    "                srs,\n",
    "                system_ratings,\n",
    "                on=\"TeamID\"\n",
    "    )\n",
    "\n",
    "    # Coaches postseason win stats\n",
    "    coaches_postseason_win_df = get_coach_win_perc(\n",
    "        dataset=mens_data, \n",
    "        regular_season=False, \n",
    "        year=year\n",
    "    ).rename(columns={\"count\": \"count_post\", \"mean\": \"mean_post\", \"std\": \"std_post\"})\n",
    "\n",
    "    # Coaches regular season win stats\n",
    "    coaches_regseason_win_df = get_coach_win_perc(\n",
    "        dataset=mens_data, \n",
    "        regular_season=True, \n",
    "        year=year\n",
    "    ).rename(columns={\"count\": \"count_reg\", \"mean\": \"mean_reg\", \"std\": \"std_reg\"})\n",
    "\n",
    "    coaches_df = pd.merge(\n",
    "        coaches_regseason_win_df,\n",
    "        coaches_postseason_win_df,\n",
    "        on=\"CoachName\",\n",
    "        how=\"left\"\n",
    "    ).fillna(0)\n",
    "\n",
    "    # Get coaches for the year and only grab the most recent coach for a certain team\n",
    "    curr_coaches = (\n",
    "        mens_data[\"MTeamCoaches\"][\n",
    "            mens_data[\"MTeamCoaches\"][\"Season\"] == year\n",
    "        ]\n",
    "        .sort_values(\"FirstDayNum\")\n",
    "        .groupby(\"TeamID\")[\"CoachName\"]\n",
    "        .last()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Get coach stats for current coaches\n",
    "    coaches_df = pd.merge(\n",
    "        curr_coaches,\n",
    "        coaches_df,\n",
    "        on=\"CoachName\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "\n",
    "    feature_df = (\n",
    "        pd.merge(\n",
    "            ratings_df,\n",
    "            coaches_df\n",
    "        )\n",
    "        .drop([\"TeamName\", \"CoachName\"], axis=1)\n",
    "    )\n",
    "\n",
    "    \n",
    "    return feature_df\n",
    "\n",
    "\n",
    "def merge_features_to_games(feature_df, post_season_df, year, training=True):\n",
    "    \n",
    "    post_season_merged = pd.merge(\n",
    "        pd.merge(\n",
    "            feature_df,\n",
    "            post_season_df,\n",
    "            on=\"TeamID\",\n",
    "        ),\n",
    "        feature_df,\n",
    "        left_on=\"OppID\",\n",
    "        right_on=\"TeamID\",\n",
    "        suffixes=(\"_team\", \"_opp\")\n",
    "    )\n",
    "    if training:\n",
    "        post_season_merged[\"win\"] = post_season_merged[\"team_score\"] > post_season_merged[\"opp_score\"]\n",
    "        post_season_merged = (\n",
    "            post_season_merged\n",
    "            .drop(\n",
    "                [\"TeamID_team\", \"team_score\", \"OppID\", \"TeamID_opp\", \"opp_score\", \"DayNum\"], \n",
    "                axis=1\n",
    "            )\n",
    "        )\n",
    "    return post_season_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['MConferenceTourneyGames', 'MGameCities', 'MMasseyOrdinals', 'MNCAATourneyCompactResults', 'MNCAATourneyDetailedResults', 'MNCAATourneySeedRoundSlots', 'MNCAATourneySeeds', 'MNCAATourneySlots', 'MRegularSeasonCompactResults', 'MRegularSeasonDetailedResults', 'MSeasons', 'MSecondaryTourneyCompactResults', 'MSecondaryTourneyTeams', 'MTeamCoaches', 'MTeamConferences', 'MTeams', 'MTeamSpellings'])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mens_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Season', 'DayNum', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'WLoc',\n",
       "       'NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR',\n",
       "       'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3',\n",
       "       'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = mens_data[\"MRegularSeasonDetailedResults\"]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2023, _ = get_season_stats(\n",
    "    mens_data,\n",
    "    detailed=True,\n",
    "    post_season=False,\n",
    "    year=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_stats(df):\n",
    "\n",
    "    df[\"margin\"] = df[\"WScore\"] - df[\"LScore\"]\n",
    "    win_df = df.rename(\n",
    "        columns={\"WTeamID\": \"team_id\", \"LTeamID\": \"opp_id\", \"WLoc\": \"Loc\"}\n",
    "    )\n",
    "    win_df = win_df.rename(columns={col: col[1:] + \"_opp\" for col in win_df.columns if col.startswith(\"L\") and col != \"Loc\"})\n",
    "    win_df = win_df.rename(columns={col: col[1:] for col in win_df.columns if col.startswith(\"W\") and not col.endswith(\"_opp\")})\n",
    "    \n",
    "    lose_df = df.rename(\n",
    "        columns={\"LTeamID\": \"team_id\", \"WTeamID\": \"opp_id\", \"WLoc\": \"Loc\"}\n",
    "    )\n",
    "    lose_df = lose_df.rename(columns={col: col[1:] for col in lose_df.columns if col.startswith(\"L\") and col != \"Loc\"})\n",
    "    lose_df = lose_df.rename(columns={col: col[1:] + \"_opp\" for col in lose_df.columns if col.startswith(\"W\")})\n",
    "    lose_df[\"Loc\"] = lose_df[\"Loc\"].apply(lambda x: \"H\" if x == \"A\" else \"A\" if x == \"H\" else \"N\")\n",
    "    lose_df[\"margin\"] = -lose_df[\"margin\"]\n",
    "\n",
    "    teams = pd.concat([win_df, lose_df], axis=0)\n",
    "\n",
    "    df = teams.groupby([\"Season\", \"team_id\"])[\n",
    "        ['FGM', 'FGA', 'FGM3', 'FGA3', 'FTM', 'FTA', 'OR', 'DR', 'Ast',\n",
    "        'TO', 'Stl', 'Blk', 'PF', 'FGM_opp', 'FGA_opp', 'FGM3_opp', 'FGA3_opp',\n",
    "        'FTM_opp', 'FTA_opp', 'OR_opp', 'DR_opp', 'Ast_opp', 'TO_opp',\n",
    "        'Stl_opp', 'Blk_opp', 'PF_opp', 'margin'\n",
    "        ]\n",
    "    ].agg([\n",
    "            (\"mean\", \"mean\"), \n",
    "            (\"quant25\" , lambda x: x.quantile(.25)), \n",
    "            (\"quant75\", lambda x: x.quantile(.75))\n",
    "        ]\n",
    "    ).reset_index()\n",
    "    df.columns = [(col + \"_\" + agg_func).strip(\"_\") for col, agg_func in zip(df.columns.get_level_values(0), df.columns.get_level_values(1))]\n",
    "\n",
    "    for col in df.columns:\n",
    "        if (\n",
    "            \"_opp\" in col\n",
    "            and col.replace(\"_opp\", \"\") in df.columns \n",
    "            and col not in [\"Season\", \"team_id\"]\n",
    "        ):\n",
    "            new_col = col.replace(\"_opp\", \"\") + \"_diff\"\n",
    "            df[new_col] = df[col.replace(\"_opp\", \"\")] - df[col]\n",
    "            df = df.drop([col.replace(\"_opp\", \"\"), col], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_team_stats(df_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>team_id</th>\n",
       "      <th>margin_mean</th>\n",
       "      <th>margin_quant25</th>\n",
       "      <th>margin_quant75</th>\n",
       "      <th>FGM_mean_diff</th>\n",
       "      <th>FGM_quant25_diff</th>\n",
       "      <th>FGM_quant75_diff</th>\n",
       "      <th>FGA_mean_diff</th>\n",
       "      <th>FGA_quant25_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>TO_quant75_diff</th>\n",
       "      <th>Stl_mean_diff</th>\n",
       "      <th>Stl_quant25_diff</th>\n",
       "      <th>Stl_quant75_diff</th>\n",
       "      <th>Blk_mean_diff</th>\n",
       "      <th>Blk_quant25_diff</th>\n",
       "      <th>Blk_quant75_diff</th>\n",
       "      <th>PF_mean_diff</th>\n",
       "      <th>PF_quant25_diff</th>\n",
       "      <th>PF_quant75_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>1102</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-13.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-2.642857</td>\n",
       "      <td>-2.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>1103</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>-6.50</td>\n",
       "      <td>6.00</td>\n",
       "      <td>-0.629630</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.148148</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.518519</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-2.592593</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>-4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>1104</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>-4.25</td>\n",
       "      <td>11.25</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.678571</td>\n",
       "      <td>2.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.75</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.214286</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>1105</td>\n",
       "      <td>-4.884615</td>\n",
       "      <td>-11.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-2.615385</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-2.75</td>\n",
       "      <td>2.653846</td>\n",
       "      <td>4.25</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.076923</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-2.115385</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>1.153846</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>1106</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>-6.75</td>\n",
       "      <td>6.75</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1.892857</td>\n",
       "      <td>2.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>-0.428571</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.035714</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>2.035714</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>2024</td>\n",
       "      <td>1474</td>\n",
       "      <td>-5.928571</td>\n",
       "      <td>-16.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>-3.785714</td>\n",
       "      <td>-3.25</td>\n",
       "      <td>-4.25</td>\n",
       "      <td>-2.285714</td>\n",
       "      <td>-5.75</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.964286</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>-2.25</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7613</th>\n",
       "      <td>2024</td>\n",
       "      <td>1475</td>\n",
       "      <td>-8.115385</td>\n",
       "      <td>-12.75</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>-1.769231</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>2.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-0.846154</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.961538</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7614</th>\n",
       "      <td>2024</td>\n",
       "      <td>1476</td>\n",
       "      <td>-13.571429</td>\n",
       "      <td>-17.25</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>-3.750000</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>-3.107143</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>...</td>\n",
       "      <td>3.25</td>\n",
       "      <td>-1.464286</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>-2.035714</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>1.464286</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7615</th>\n",
       "      <td>2024</td>\n",
       "      <td>1477</td>\n",
       "      <td>-10.520000</td>\n",
       "      <td>-22.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-3.800000</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>-6.00</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>2.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7616</th>\n",
       "      <td>2024</td>\n",
       "      <td>1478</td>\n",
       "      <td>-3.400000</td>\n",
       "      <td>-16.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>-1.800000</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7617 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Season  team_id  margin_mean  margin_quant25  margin_quant75  \\\n",
       "0       2003     1102     0.250000          -13.00           10.00   \n",
       "1       2003     1103     0.629630           -6.50            6.00   \n",
       "2       2003     1104     4.285714           -4.25           11.25   \n",
       "3       2003     1105    -4.884615          -11.75            0.50   \n",
       "4       2003     1106    -0.142857           -6.75            6.75   \n",
       "...      ...      ...          ...             ...             ...   \n",
       "7612    2024     1474    -5.928571          -16.00            3.75   \n",
       "7613    2024     1475    -8.115385          -12.75           -2.00   \n",
       "7614    2024     1476   -13.571429          -17.25           -5.00   \n",
       "7615    2024     1477   -10.520000          -22.00            2.00   \n",
       "7616    2024     1478    -3.400000          -16.00            8.00   \n",
       "\n",
       "      FGM_mean_diff  FGM_quant25_diff  FGM_quant75_diff  FGA_mean_diff  \\\n",
       "0         -0.142857              0.00              0.00      -2.642857   \n",
       "1         -0.629630             -1.50              1.00      -1.148148   \n",
       "2          0.785714             -1.00              2.00       1.678571   \n",
       "3         -2.615385             -1.25             -2.75       2.653846   \n",
       "4          1.714286              1.00              2.25       1.892857   \n",
       "...             ...               ...               ...            ...   \n",
       "7612      -3.785714             -3.25             -4.25      -2.285714   \n",
       "7613      -1.769231             -2.00             -1.50       0.423077   \n",
       "7614      -3.750000             -2.00             -3.50      -3.107143   \n",
       "7615      -3.800000             -2.00             -6.00       2.200000   \n",
       "7616      -1.800000             -3.00             -1.00      -0.200000   \n",
       "\n",
       "      FGA_quant25_diff  ...  TO_quant75_diff  Stl_mean_diff  Stl_quant25_diff  \\\n",
       "0                -2.75  ...             0.00       0.535714              1.00   \n",
       "1                -1.50  ...            -2.50       0.851852              0.00   \n",
       "2                 2.00  ...            -2.75       1.071429              1.00   \n",
       "3                 4.25  ...            -1.00      -0.076923             -0.75   \n",
       "4                 2.00  ...             3.50      -0.428571             -0.75   \n",
       "...                ...  ...              ...            ...               ...   \n",
       "7612             -5.75  ...             1.00       0.142857              1.00   \n",
       "7613              2.00  ...             2.00      -0.846154              0.00   \n",
       "7614             -1.25  ...             3.25      -1.464286             -1.00   \n",
       "7615              2.00  ...            -2.00       1.600000             -1.00   \n",
       "7616              1.00  ...            -3.00       0.880000              1.00   \n",
       "\n",
       "      Stl_quant75_diff  Blk_mean_diff  Blk_quant25_diff  Blk_quant75_diff  \\\n",
       "0                 0.00       0.214286              1.00             -1.00   \n",
       "1                 1.00      -0.518519             -0.50             -0.50   \n",
       "2                 1.25       0.607143              1.00              0.00   \n",
       "3                 1.00      -2.115385             -1.25             -2.00   \n",
       "4                 0.75      -0.035714              0.00             -0.75   \n",
       "...                ...            ...               ...               ...   \n",
       "7612              1.00      -1.964286             -2.00             -2.25   \n",
       "7613             -2.00      -1.000000             -1.00             -1.00   \n",
       "7614             -2.00      -2.035714             -1.75             -3.00   \n",
       "7615              2.00       0.960000              0.00              2.00   \n",
       "7616              1.00       0.440000              1.00              1.00   \n",
       "\n",
       "      PF_mean_diff  PF_quant25_diff  PF_quant75_diff  \n",
       "0         0.392857             0.75             0.75  \n",
       "1        -2.592593            -2.00            -4.00  \n",
       "2        -1.214286            -1.75            -1.00  \n",
       "3         1.153846             1.00             0.25  \n",
       "4         2.035714             3.00             1.00  \n",
       "...            ...              ...              ...  \n",
       "7612     -0.714286            -1.25            -2.00  \n",
       "7613      2.961538             3.00             1.50  \n",
       "7614      1.464286             1.00             1.00  \n",
       "7615      3.320000             3.00             2.00  \n",
       "7616      1.800000             2.00             1.00  \n",
       "\n",
       "[7617 rows x 44 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def get_advanced_stats(year):\n",
    "    \n",
    "    ################################## TEAM ##########################################\n",
    "\n",
    "\n",
    "    # URL of the page you want to scrape\n",
    "    url = f'https://www.sports-reference.com/cbb/seasons/men/{year}-advanced-school-stats.html'\n",
    "\n",
    "    # Send a GET request to the webpage\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the table by ID or class\n",
    "    table = soup.find('table', {'id': 'adv_school_stats'})\n",
    "\n",
    "    # Extract the column headers from the <thead> part of the table\n",
    "    headers = [header.text for header in table.find('thead').find_all('th')]\n",
    "    headers = [\n",
    "        i for i in headers \n",
    "        if (i != \"\") \n",
    "        and (i != \"\\xa0\") \n",
    "        and (i not in ['School Advanced', 'Overall', 'Conf.', 'Home', 'Away', 'Points', 'Opponent Advanced', 'Rk'])\n",
    "    ]\n",
    "\n",
    "    # Extract rows from the <tbody> part of the table\n",
    "    rows = table.find('tbody').find_all('tr')\n",
    "\n",
    "    # Extract data from each row\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        cols = [ele.text.strip() for ele in cols if ele.text.strip() != \"\"]\n",
    "        data.append(cols)  # Get rid of empty values\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame(data, columns=headers)  # headers[1:] because the first header is usually the rank or an empty string\n",
    "\n",
    "\n",
    "    ################################## OPP ##########################################\n",
    "\n",
    "    # URL of the page you want to scrape\n",
    "    url = f'https://www.sports-reference.com/cbb/seasons/men/{year}-advanced-opponent-stats.html'\n",
    "\n",
    "    # Send a GET request to the webpage\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the table by ID or class\n",
    "    table = soup.find('table', {'id': 'adv_opp_stats'})\n",
    "\n",
    "    # Extract the column headers from the <thead> part of the table\n",
    "    headers = [header.text for header in table.find('thead').find_all('th')]\n",
    "    headers = [\n",
    "        i for i in headers \n",
    "        if (i != \"\") \n",
    "        and (i != \"\\xa0\") \n",
    "        and (i not in ['Overall', 'Conf.', 'Home', 'Away', 'Points', 'Opponent Advanced', 'Rk'])\n",
    "    ]\n",
    "\n",
    "    # Extract rows from the <tbody> part of the table\n",
    "    rows = table.find('tbody').find_all('tr')\n",
    "\n",
    "    # Extract data from each row\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        cols = [ele.text.strip() for ele in cols if ele.text.strip() != \"\"]\n",
    "        data.append(cols)  # Get rid of empty values\n",
    "\n",
    "    # Create the DataFrame\n",
    "    opp_df = pd.DataFrame(data, columns=headers)  # headers[1:] because the first header is usually the rank or an empty string\n",
    "\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    opp_df = (\n",
    "        opp_df\n",
    "        .dropna()\n",
    "        .reset_index(drop=True)\n",
    "        .drop([\"G\", \"W\", \"L\", \"W-L%\", \"SRS\", \"SOS\", \"W\", \"L\", \"W\", \"L\", \"W\", \"L\", \"Tm.\", \"Opp.\"], axis=1)\n",
    "        .rename(columns={col: col + \"_opp\" for col in opp_df.columns if col != \"School\"})\n",
    "    )\n",
    "    res = pd.merge(df, opp_df, on=\"School\")\n",
    "\n",
    "    res[\"School\"] = res[\"School\"].str.replace(\"NCAA\",\"\").str.strip()\n",
    "    res[\"Season\"] = year\n",
    "    return res\n",
    "\n",
    "\n",
    "# Works 2010 and on\n",
    "advanced_stats = dict()\n",
    "for year in range(2010, 2025):\n",
    "    print(year)\n",
    "    advanced_stats[year] = get_advanced_stats(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(advanced_stats.values(), ignore_index=True).to_csv(\"../data/stats/advanced_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(advanced_stats.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>School</th>\n",
       "      <th>G</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>W-L%</th>\n",
       "      <th>SRS</th>\n",
       "      <th>SOS</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>W</th>\n",
       "      <th>...</th>\n",
       "      <th>TS%_opp</th>\n",
       "      <th>TRB%_opp</th>\n",
       "      <th>AST%_opp</th>\n",
       "      <th>STL%_opp</th>\n",
       "      <th>BLK%_opp</th>\n",
       "      <th>eFG%_opp</th>\n",
       "      <th>TOV%_opp</th>\n",
       "      <th>ORB%_opp</th>\n",
       "      <th>FT/FGA_opp</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Air Force</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>.323</td>\n",
       "      <td>-4.90</td>\n",
       "      <td>3.13</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>.558</td>\n",
       "      <td>53.2</td>\n",
       "      <td>59.8</td>\n",
       "      <td>9.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>.527</td>\n",
       "      <td>17.2</td>\n",
       "      <td>30.4</td>\n",
       "      <td>.273</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Akron</td>\n",
       "      <td>35</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>.686</td>\n",
       "      <td>2.82</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>.510</td>\n",
       "      <td>48.4</td>\n",
       "      <td>47.9</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6.6</td>\n",
       "      <td>.464</td>\n",
       "      <td>18.1</td>\n",
       "      <td>33.3</td>\n",
       "      <td>.287</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>32</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>.531</td>\n",
       "      <td>10.34</td>\n",
       "      <td>6.62</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>.509</td>\n",
       "      <td>49.5</td>\n",
       "      <td>48.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>10.1</td>\n",
       "      <td>.477</td>\n",
       "      <td>18.0</td>\n",
       "      <td>34.2</td>\n",
       "      <td>.242</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama A&amp;M</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>.407</td>\n",
       "      <td>-20.19</td>\n",
       "      <td>-13.71</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>.500</td>\n",
       "      <td>53.2</td>\n",
       "      <td>56.8</td>\n",
       "      <td>11.3</td>\n",
       "      <td>11.4</td>\n",
       "      <td>.469</td>\n",
       "      <td>21.4</td>\n",
       "      <td>39.4</td>\n",
       "      <td>.261</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama St</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>.516</td>\n",
       "      <td>-14.41</td>\n",
       "      <td>-12.02</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>.523</td>\n",
       "      <td>48.7</td>\n",
       "      <td>49.1</td>\n",
       "      <td>11.7</td>\n",
       "      <td>10.2</td>\n",
       "      <td>.482</td>\n",
       "      <td>19.9</td>\n",
       "      <td>31.4</td>\n",
       "      <td>.320</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5235</th>\n",
       "      <td>Wright St</td>\n",
       "      <td>32</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>.563</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-3.40</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>.568</td>\n",
       "      <td>48.4</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>.542</td>\n",
       "      <td>14.6</td>\n",
       "      <td>27.9</td>\n",
       "      <td>.208</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5236</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>.469</td>\n",
       "      <td>0.96</td>\n",
       "      <td>4.99</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>.551</td>\n",
       "      <td>49.2</td>\n",
       "      <td>48.5</td>\n",
       "      <td>11.9</td>\n",
       "      <td>11.1</td>\n",
       "      <td>.522</td>\n",
       "      <td>14.3</td>\n",
       "      <td>28.8</td>\n",
       "      <td>.201</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237</th>\n",
       "      <td>Xavier</td>\n",
       "      <td>33</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>.485</td>\n",
       "      <td>12.24</td>\n",
       "      <td>10.94</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>.528</td>\n",
       "      <td>48.5</td>\n",
       "      <td>60.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>11.5</td>\n",
       "      <td>.496</td>\n",
       "      <td>14.1</td>\n",
       "      <td>28.9</td>\n",
       "      <td>.215</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5238</th>\n",
       "      <td>Yale</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>.710</td>\n",
       "      <td>4.80</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>.518</td>\n",
       "      <td>46.6</td>\n",
       "      <td>57.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>.484</td>\n",
       "      <td>14.5</td>\n",
       "      <td>23.5</td>\n",
       "      <td>.202</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5239</th>\n",
       "      <td>Youngstown St</td>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>.688</td>\n",
       "      <td>1.20</td>\n",
       "      <td>-4.87</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>.509</td>\n",
       "      <td>46.2</td>\n",
       "      <td>54.8</td>\n",
       "      <td>8.4</td>\n",
       "      <td>7.7</td>\n",
       "      <td>.479</td>\n",
       "      <td>14.7</td>\n",
       "      <td>27.9</td>\n",
       "      <td>.197</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5240 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             School   G   W   L  W-L%     SRS     SOS   W   L   W  ...  \\\n",
       "0         Air Force  31  10  21  .323   -4.90    3.13   1  15   8  ...   \n",
       "1             Akron  35  24  11  .686    2.82   -1.50  12   4  13  ...   \n",
       "2           Alabama  32  17  15  .531   10.34    6.62   6  10  11  ...   \n",
       "3       Alabama A&M  27  11  16  .407  -20.19  -13.71   8  10   8  ...   \n",
       "4        Alabama St  31  16  15  .516  -14.41  -12.02  12   6   9  ...   \n",
       "...             ...  ..  ..  ..   ...     ...     ...  ..  ..  ..  ...   \n",
       "5235      Wright St  32  18  14  .563    0.00   -3.40  13   7   9  ...   \n",
       "5236        Wyoming  32  15  17  .469    0.96    4.99   8  10   9  ...   \n",
       "5237         Xavier  33  16  17  .485   12.24   10.94   9  11  11  ...   \n",
       "5238           Yale  31  22   9  .710    4.80   -0.61  11   3   9  ...   \n",
       "5239  Youngstown St  32  22  10  .688    1.20   -4.87  14   6  14  ...   \n",
       "\n",
       "     TS%_opp TRB%_opp AST%_opp STL%_opp BLK%_opp eFG%_opp TOV%_opp ORB%_opp  \\\n",
       "0       .558     53.2     59.8      9.7     10.0     .527     17.2     30.4   \n",
       "1       .510     48.4     47.9     10.1      6.6     .464     18.1     33.3   \n",
       "2       .509     49.5     48.6      8.8     10.1     .477     18.0     34.2   \n",
       "3       .500     53.2     56.8     11.3     11.4     .469     21.4     39.4   \n",
       "4       .523     48.7     49.1     11.7     10.2     .482     19.9     31.4   \n",
       "...      ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "5235    .568     48.4     45.0     10.0      6.2     .542     14.6     27.9   \n",
       "5236    .551     49.2     48.5     11.9     11.1     .522     14.3     28.8   \n",
       "5237    .528     48.5     60.1      8.6     11.5     .496     14.1     28.9   \n",
       "5238    .518     46.6     57.9      8.1      8.6     .484     14.5     23.5   \n",
       "5239    .509     46.2     54.8      8.4      7.7     .479     14.7     27.9   \n",
       "\n",
       "     FT/FGA_opp Season  \n",
       "0          .273   2010  \n",
       "1          .287   2010  \n",
       "2          .242   2010  \n",
       "3          .261   2010  \n",
       "4          .320   2010  \n",
       "...         ...    ...  \n",
       "5235       .208   2024  \n",
       "5236       .201   2024  \n",
       "5237       .215   2024  \n",
       "5238       .202   2024  \n",
       "5239       .197   2024  \n",
       "\n",
       "[5240 rows x 42 columns]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_season_data = dict()\n",
    "for year in range(2010, 2025):\n",
    "    post_season_data[year] = get_post_season(mens_data, year)\n",
    "post_season_data = pd.concat(post_season_data.values(), ignore_index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_season_teams = pd.merge(\n",
    "    pd.DataFrame({\"TeamID\": list(set(list(post_season_data[\"TeamID\"]) + list(post_season_data[\"OppID\"])))}),\n",
    "    mens_data[\"MTeams\"],\n",
    "    on=\"TeamID\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    'Abilene Chr': 'Abilene Christian',\n",
    "    'American Univ': \"American\", \n",
    "    'Ark Little Rock': \"Little Rock\", \n",
    "    'Ark Pine Bluff': 'Arkansas-Pine Bluff',\n",
    "    'BYU': \"Brigham Young\", \n",
    "    'Boston Univ': \"Boston University\", \n",
    "    'CS Bakersfield': \"Cal St Bakersfield\", \n",
    "    'CS Fullerton': \"Cal St Fullerton\", \n",
    "    'Coastal Car': \"Coastal Carolina\",\n",
    "    'Col Charleston': \"College of Charleston\", \n",
    "    'Detroit': \"Detroit Mercy\", \n",
    "    'E Kentucky': \"Eastern Kentucky\", \n",
    "    'E Washington': \"Eastern Washington\", \n",
    "    'ETSU': \"East Tennessee St\",\n",
    "    'F Dickinson': \"FDU\", \n",
    "    'FL Atlantic': \"Florida Atlantic\", \n",
    "    'FL Gulf Coast': \"Florida Gulf Coast\", \n",
    "    'G Washington': \"George Washington\",\n",
    "    'Gardner Webb': \"Gardner-Webb\", \n",
    "    'Kennesaw': \"Kennesaw St\", \n",
    "    'Kent': \"Kent St\", \n",
    "    'LIU Brooklyn': \"Long Island University\",\n",
    "    'LSU': \"Louisiana\", \n",
    "    'Loyola MD': \"Loyola (MD)\",\n",
    "    'Loyola-Chicago': \"Loyola (IL)\", \n",
    "    'MS Valley St': \"Mississippi Valley St\", \n",
    "    'MTSU': \"Middle Tennessee\", \n",
    "    'Miami FL': \"Miami (FL)\", \n",
    "    \"Mt St Mary's\": \"Mount St. Mary's\",\n",
    "    'N Colorado': \"Northern Colorado\", \n",
    "    'N Dakota St': \"North Dakota St\", \n",
    "    'N Kentucky': \"Western Kentucky\", \n",
    "    'NC A&T': \"North Carolina A&T\", \n",
    "    'NC Central': \"North Carolina Central\",\n",
    "    'NC State': \"NC St\", \n",
    "    # 'Northwestern State': \"Northwestern St\", \n",
    "    'Northwestern LA': \"Northwestern St\", \n",
    "    'Penn': \"Pennsylvania\", \n",
    "    'S Dakota St': \"South Dakota St\", \n",
    "    'SE Missouri St': \"Southeast Missouri St\",\n",
    "    'SF Austin': \"Stephen F. Austin\", \n",
    "    'SMU': \"Southern Methodist\", \n",
    "    'SUNY Albany': \"Albany (NY)\", \n",
    "    'Sam Houston St': \"Sam Houston\", \n",
    "    'Southern Miss': \"Southern Mississippi\",\n",
    "    'Southern Univ': \"Southern\", \n",
    "    'St Bonaventure': \"St. Bonaventure\", \n",
    "    \"St John's\": \"St. John's (NY)\", \n",
    "    \"St Joseph's PA\": \"Saint Joseph's\",\n",
    "    'St Louis': \"Saint Louis\", \n",
    "    \"St Mary's CA\": \"Saint Mary's (CA)\", \n",
    "    \"St Peter's\": \"Saint Peter's\", \n",
    "    'TAM C. Christi': \"Texas A&M-Corpus Christi\",\n",
    "    'TX Southern': \"Texas Southern\", \n",
    "    'UMBC': \"Maryland-Baltimore County\", \n",
    "    'UNLV': \"Nevada-Las Vegas\", \n",
    "    'USC': \"Southern California\", \n",
    "    'UT San Antonio': \"UTSA\", \n",
    "    'VCU': \"Virginia Commonwealth\",\n",
    "    'W Michigan': \"Western Michigan\", \n",
    "    'WI Green Bay': \"Green Bay\", \n",
    "    'WI Milwaukee': \"Milwaukee\", \n",
    "    'WKU': \"Western Kentucky\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"School\"] = df[\"School\"].str.replace(\"State\", \"St\")\n",
    "post_season_teams[\"TeamName\"] = post_season_teams[\"TeamName\"].apply(lambda x: mapping[x] if x in mapping else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TeamID</th>\n",
       "      <th>TeamName</th>\n",
       "      <th>FirstD1Season</th>\n",
       "      <th>LastD1Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1101</td>\n",
       "      <td>Abilene Christian</td>\n",
       "      <td>2014</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1103</td>\n",
       "      <td>Akron</td>\n",
       "      <td>1985</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1104</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1985</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1106</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>1985</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1107</td>\n",
       "      <td>Albany (NY)</td>\n",
       "      <td>2000</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>1459</td>\n",
       "      <td>Wofford</td>\n",
       "      <td>1996</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>1460</td>\n",
       "      <td>Wright St</td>\n",
       "      <td>1988</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>1461</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>1985</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>1462</td>\n",
       "      <td>Xavier</td>\n",
       "      <td>1985</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>1463</td>\n",
       "      <td>Yale</td>\n",
       "      <td>1985</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>236 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TeamID           TeamName  FirstD1Season  LastD1Season\n",
       "0      1101  Abilene Christian           2014          2024\n",
       "1      1103              Akron           1985          2024\n",
       "2      1104            Alabama           1985          2024\n",
       "3      1106         Alabama St           1985          2024\n",
       "4      1107        Albany (NY)           2000          2024\n",
       "..      ...                ...            ...           ...\n",
       "231    1459            Wofford           1996          2024\n",
       "232    1460          Wright St           1988          2024\n",
       "233    1461            Wyoming           1985          2024\n",
       "234    1462             Xavier           1985          2024\n",
       "235    1463               Yale           1985          2024\n",
       "\n",
       "[236 rows x 4 columns]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_season_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(\n",
    "    post_season_teams,\n",
    "    df,\n",
    "    left_on=\"TeamName\",\n",
    "    right_on=\"School\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: TeamID, dtype: int64)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.groupby(\"TeamName\").count()[\"TeamID\"][merged.groupby(\"TeamName\").count()[\"TeamID\"].index==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#     'Abilene Chr': 'Abilene Christian',\n",
    "#     'American Univ': \"American\", \n",
    "#     'Ark Little Rock': \"Little Rock\", \n",
    "#     'Ark Pine Bluff': 'Arkansas-Pine Bluff',\n",
    "#     'BYU': \"Brigham Young\", \n",
    "#     'Boston Univ': \"Boston University\", \n",
    "#     'CS Bakersfield': \"Cal St Bakersfield\", \n",
    "#     'CS Fullerton': \"Cal St Fullerton\", \n",
    "#     'Coastal Car': \"Coastal Carolina\",\n",
    "#     'Col Charleston': \"College of Charleston\", \n",
    "#     'Detroit': \"Detroit Mercy\", \n",
    "#     'E Kentucky': \"Eastern Kentucky\", \n",
    "#     'E Washington': \"Eastern Washington\", \n",
    "#     'ETSU': \"East Tennessee St\",\n",
    "#     'F Dickinson': \"FDU\", \n",
    "#     'FL Atlantic': \"Florida Atlantic\", \n",
    "#     'FL Gulf Coast': \"Florida Gulf Coast\", \n",
    "#     'G Washington': \"George Washington\",\n",
    "#     'Gardner Webb': \"Gardner-Webb\", \n",
    "#     'Kennesaw': \"Kennesaw St\", \n",
    "#     'Kent': \"Kent St\", \n",
    "#     'LIU Brooklyn': \"Long Island University\",\n",
    "#     'LSU': \"Louisiana\", \n",
    "#     'Loyola MD': \"Loyola (MD)\",\n",
    "#     'Loyola-Chicago': \"Loyala (IL)\", \n",
    "#     'MS Valley St': \"Mississippi Valley State\", \n",
    "#     'MTSU': \"Middle Tennessee\", \n",
    "#     'Miami FL': \"Miami (FL)\", \n",
    "#     \"Mt St Mary's\": \"Mount St Mary's\",\n",
    "#     'N Colorado': \"North Colorado\", \n",
    "#     'N Dakota St': \"North Dakota St\", \n",
    "#     'N Kentucky': \"Western Kentucky\", \n",
    "#     'NC A&T': \"North Caroline A&T\", \n",
    "#     'NC Central': \"North Carolina Central\",\n",
    "#     'NC State': \"North Carolina St\", \n",
    "#     'Northwestern LA': \"Northwestern State\", \n",
    "#     'Penn': \"Pennsylvania\", \n",
    "#     'S Dakota St': \"South Dakota St\", \n",
    "#     'SE Missouri St': \"Southeastern Missouri St\",\n",
    "#     'SF Austin': \"Stephen F. Austin\", \n",
    "#     'SMU': \"Southern Methodist\", \n",
    "#     'SUNY Albany': \"Albany (NY)\", \n",
    "#     'Sam Houston St': \"Sam Houston\", \n",
    "#     'Southern Miss': \"Southern Mississippi\",\n",
    "#     'Southern Univ': \"Southern\", \n",
    "#     'St Bonaventure': \"St. Bonaventure\", \n",
    "#     \"St John's\": \"St. John's (NY)\", \n",
    "#     \"St Joseph's PA\": \"Saint Joseph's\",\n",
    "#     'St Louis': \"Saint Louis\", \n",
    "#     \"St Mary's CA\": \"Saint Mary's (CA)\", \n",
    "#     \"St Peter's\": \"Saint Peter's\", \n",
    "#     'TAM C. Christi': \"Texas A&M-Corpus Christi\",\n",
    "#     'TX Southern': \"Texas Southern\", \n",
    "#     'UMBC': \"Maryland-Baltimore County\", \n",
    "#     'UNLV': \"Nevada-Las Vegas\", \n",
    "#     'USC': \"Southern California\", \n",
    "#     'UT San Antonio': \"UTSA\", \n",
    "#     'VCU': \"Virginia Commonwealth\",\n",
    "#     'W Michigan': \"Western Michigan\", \n",
    "#     'WI Green Bay': \"Green Bay\", \n",
    "#     'WI Milwaukee': \"Milwaukee\", \n",
    "#     'WKU': \"Western Kentucky\",\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.drop(\"School\", axis=1).to_csv(\"../data/stats/advanced_stats_tournament_teams.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TeamID</th>\n",
       "      <th>TeamName</th>\n",
       "      <th>FirstD1Season</th>\n",
       "      <th>LastD1Season</th>\n",
       "      <th>School</th>\n",
       "      <th>G</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>W-L%</th>\n",
       "      <th>SRS</th>\n",
       "      <th>...</th>\n",
       "      <th>TS%_opp</th>\n",
       "      <th>TRB%_opp</th>\n",
       "      <th>AST%_opp</th>\n",
       "      <th>STL%_opp</th>\n",
       "      <th>BLK%_opp</th>\n",
       "      <th>eFG%_opp</th>\n",
       "      <th>TOV%_opp</th>\n",
       "      <th>ORB%_opp</th>\n",
       "      <th>FT/FGA_opp</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1101</td>\n",
       "      <td>Abilene Christian</td>\n",
       "      <td>2014</td>\n",
       "      <td>2024</td>\n",
       "      <td>Abilene Christian</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>.355</td>\n",
       "      <td>-19.60</td>\n",
       "      <td>...</td>\n",
       "      <td>.558</td>\n",
       "      <td>49.8</td>\n",
       "      <td>53.6</td>\n",
       "      <td>9.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>.518</td>\n",
       "      <td>17.8</td>\n",
       "      <td>30.2</td>\n",
       "      <td>.323</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1101</td>\n",
       "      <td>Abilene Christian</td>\n",
       "      <td>2014</td>\n",
       "      <td>2024</td>\n",
       "      <td>Abilene Christian</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>.323</td>\n",
       "      <td>-17.20</td>\n",
       "      <td>...</td>\n",
       "      <td>.573</td>\n",
       "      <td>55.4</td>\n",
       "      <td>50.1</td>\n",
       "      <td>8.8</td>\n",
       "      <td>11.6</td>\n",
       "      <td>.539</td>\n",
       "      <td>19.2</td>\n",
       "      <td>33.4</td>\n",
       "      <td>.325</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>Abilene Christian</td>\n",
       "      <td>2014</td>\n",
       "      <td>2024</td>\n",
       "      <td>Abilene Christian</td>\n",
       "      <td>31</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>.419</td>\n",
       "      <td>-13.93</td>\n",
       "      <td>...</td>\n",
       "      <td>.565</td>\n",
       "      <td>51.0</td>\n",
       "      <td>47.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>8.6</td>\n",
       "      <td>.527</td>\n",
       "      <td>18.2</td>\n",
       "      <td>26.9</td>\n",
       "      <td>.313</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1101</td>\n",
       "      <td>Abilene Christian</td>\n",
       "      <td>2014</td>\n",
       "      <td>2024</td>\n",
       "      <td>Abilene Christian</td>\n",
       "      <td>29</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>.448</td>\n",
       "      <td>-11.86</td>\n",
       "      <td>...</td>\n",
       "      <td>.553</td>\n",
       "      <td>52.9</td>\n",
       "      <td>55.5</td>\n",
       "      <td>8.9</td>\n",
       "      <td>8.8</td>\n",
       "      <td>.522</td>\n",
       "      <td>18.5</td>\n",
       "      <td>30.1</td>\n",
       "      <td>.287</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1101</td>\n",
       "      <td>Abilene Christian</td>\n",
       "      <td>2014</td>\n",
       "      <td>2024</td>\n",
       "      <td>Abilene Christian</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>.500</td>\n",
       "      <td>-9.14</td>\n",
       "      <td>...</td>\n",
       "      <td>.540</td>\n",
       "      <td>50.3</td>\n",
       "      <td>48.1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>7.5</td>\n",
       "      <td>.499</td>\n",
       "      <td>19.5</td>\n",
       "      <td>28.5</td>\n",
       "      <td>.298</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3503</th>\n",
       "      <td>1463</td>\n",
       "      <td>Yale</td>\n",
       "      <td>1985</td>\n",
       "      <td>2024</td>\n",
       "      <td>Yale</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>.733</td>\n",
       "      <td>5.52</td>\n",
       "      <td>...</td>\n",
       "      <td>.509</td>\n",
       "      <td>47.1</td>\n",
       "      <td>48.9</td>\n",
       "      <td>9.4</td>\n",
       "      <td>7.9</td>\n",
       "      <td>.471</td>\n",
       "      <td>13.5</td>\n",
       "      <td>24.1</td>\n",
       "      <td>.223</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3504</th>\n",
       "      <td>1463</td>\n",
       "      <td>Yale</td>\n",
       "      <td>1985</td>\n",
       "      <td>2024</td>\n",
       "      <td>Yale</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>.767</td>\n",
       "      <td>6.63</td>\n",
       "      <td>...</td>\n",
       "      <td>.492</td>\n",
       "      <td>45.2</td>\n",
       "      <td>50.9</td>\n",
       "      <td>9.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>.459</td>\n",
       "      <td>15.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>.183</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3505</th>\n",
       "      <td>1463</td>\n",
       "      <td>Yale</td>\n",
       "      <td>1985</td>\n",
       "      <td>2024</td>\n",
       "      <td>Yale</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>.613</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>.518</td>\n",
       "      <td>49.8</td>\n",
       "      <td>48.5</td>\n",
       "      <td>10.3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>.486</td>\n",
       "      <td>16.5</td>\n",
       "      <td>26.3</td>\n",
       "      <td>.219</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3506</th>\n",
       "      <td>1463</td>\n",
       "      <td>Yale</td>\n",
       "      <td>1985</td>\n",
       "      <td>2024</td>\n",
       "      <td>Yale</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>.700</td>\n",
       "      <td>7.81</td>\n",
       "      <td>...</td>\n",
       "      <td>.498</td>\n",
       "      <td>45.8</td>\n",
       "      <td>50.4</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>.461</td>\n",
       "      <td>16.5</td>\n",
       "      <td>23.1</td>\n",
       "      <td>.227</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3507</th>\n",
       "      <td>1463</td>\n",
       "      <td>Yale</td>\n",
       "      <td>1985</td>\n",
       "      <td>2024</td>\n",
       "      <td>Yale</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>.710</td>\n",
       "      <td>4.80</td>\n",
       "      <td>...</td>\n",
       "      <td>.518</td>\n",
       "      <td>46.6</td>\n",
       "      <td>57.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>.484</td>\n",
       "      <td>14.5</td>\n",
       "      <td>23.5</td>\n",
       "      <td>.202</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3508 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TeamID           TeamName  FirstD1Season  LastD1Season  \\\n",
       "0       1101  Abilene Christian           2014          2024   \n",
       "1       1101  Abilene Christian           2014          2024   \n",
       "2       1101  Abilene Christian           2014          2024   \n",
       "3       1101  Abilene Christian           2014          2024   \n",
       "4       1101  Abilene Christian           2014          2024   \n",
       "...      ...                ...            ...           ...   \n",
       "3503    1463               Yale           1985          2024   \n",
       "3504    1463               Yale           1985          2024   \n",
       "3505    1463               Yale           1985          2024   \n",
       "3506    1463               Yale           1985          2024   \n",
       "3507    1463               Yale           1985          2024   \n",
       "\n",
       "                 School   G   W   L  W-L%     SRS  ... TS%_opp TRB%_opp  \\\n",
       "0     Abilene Christian  31  11  20  .355  -19.60  ...    .558     49.8   \n",
       "1     Abilene Christian  31  10  21  .323  -17.20  ...    .573     55.4   \n",
       "2     Abilene Christian  31  13  18  .419  -13.93  ...    .565     51.0   \n",
       "3     Abilene Christian  29  13  16  .448  -11.86  ...    .553     52.9   \n",
       "4     Abilene Christian  32  16  16  .500   -9.14  ...    .540     50.3   \n",
       "...                 ...  ..  ..  ..   ...     ...  ...     ...      ...   \n",
       "3503               Yale  30  22   8  .733    5.52  ...    .509     47.1   \n",
       "3504               Yale  30  23   7  .767    6.63  ...    .492     45.2   \n",
       "3505               Yale  31  19  12  .613   -0.10  ...    .518     49.8   \n",
       "3506               Yale  30  21   9  .700    7.81  ...    .498     45.8   \n",
       "3507               Yale  31  22   9  .710    4.80  ...    .518     46.6   \n",
       "\n",
       "     AST%_opp STL%_opp BLK%_opp eFG%_opp TOV%_opp ORB%_opp FT/FGA_opp Season  \n",
       "0        53.6      9.7     12.0     .518     17.8     30.2       .323   2014  \n",
       "1        50.1      8.8     11.6     .539     19.2     33.4       .325   2015  \n",
       "2        47.5      7.3      8.6     .527     18.2     26.9       .313   2016  \n",
       "3        55.5      8.9      8.8     .522     18.5     30.1       .287   2017  \n",
       "4        48.1      8.9      7.5     .499     19.5     28.5       .298   2018  \n",
       "...       ...      ...      ...      ...      ...      ...        ...    ...  \n",
       "3503     48.9      9.4      7.9     .471     13.5     24.1       .223   2019  \n",
       "3504     50.9      9.6      8.9     .459     15.5     21.0       .183   2020  \n",
       "3505     48.5     10.3      9.5     .486     16.5     26.3       .219   2022  \n",
       "3506     50.4      8.5      7.3     .461     16.5     23.1       .227   2023  \n",
       "3507     57.9      8.1      8.6     .484     14.5     23.5       .202   2024  \n",
       "\n",
       "[3508 rows x 46 columns]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mm_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
